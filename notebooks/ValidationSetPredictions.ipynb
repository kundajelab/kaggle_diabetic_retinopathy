{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (Ubuntu 4.8.5-4ubuntu2) 4.8.5\r\n",
      "Copyright (C) 2015 Free Software Foundation, Inc.\r\n",
      "This is free software; see the source for copying conditions.  There is NO\r\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-7.0/bin/nvcc\r\n"
     ]
    }
   ],
   "source": [
    "!which nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n",
      "/users/avanti/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import pandas as p\n",
    "import lasagne as nn\n",
    "\n",
    "from utils import hms, architecture_string, get_img_ids_from_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "rcParams['figure.figsize'] = 16, 6\n",
    "# rcParams['text.color'] = 'red'\n",
    "# rcParams['xtick.color'] = 'red'\n",
    "# rcParams['ytick.color'] = 'red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the dump of the trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump_path = '../dumps/2015_07_17_123003.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_data = pickle.load(open(dump_path, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's set the in and output layers to some local vars.\n",
    "l_out = model_data['l_out']\n",
    "l_ins = model_data['l_ins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create mirror non-dnn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some info about the architecture of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/avanti/Lasagne/lasagne/layers/helper.py:69: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n",
      "  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n"
     ]
    }
   ],
   "source": [
    "model_arch = architecture_string(model_data['l_out'])\n",
    "\n",
    "num_params = nn.layers.count_params(l_out)\n",
    "model_arch += \"\\nNumber of parameters: %d.\\n\\n\" % num_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up some Theano / Lasagne things to get some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 64.\n",
      "Chunk size: 256.\n"
     ]
    }
   ],
   "source": [
    "chunk_size = model_data['chunk_size'] * 2\n",
    "batch_size = model_data['batch_size']\n",
    "\n",
    "print \"Batch size: %i.\" % batch_size\n",
    "print \"Chunk size: %i.\" % chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = nn.layers.get_output(l_out, deterministic=True)\n",
    "nondeterministic_output = nn.layers.get_output(l_out, deterministic=False)\n",
    "input_ndims = [len(nn.layers.get_output_shape(l_in))\n",
    "               for l_in in l_ins]\n",
    "xs_shared = [nn.utils.shared_empty(dim=ndim)\n",
    "             for ndim in input_ndims]\n",
    "idx = T.lscalar('idx')\n",
    "\n",
    "givens = {}\n",
    "for l_in, x_shared in zip(l_ins, xs_shared):\n",
    "    givens[l_in.input_var] = x_shared[idx * batch_size:(idx + 1) * batch_size]\n",
    "\n",
    "compute_output = theano.function(\n",
    "    [idx],\n",
    "    output,\n",
    "    givens=givens,\n",
    "    on_unused_input='ignore'\n",
    ")\n",
    "\n",
    "compute_nondeterministic_output = theano.function(\n",
    "    [idx],\n",
    "    nondeterministic_output,\n",
    "    givens=givens,\n",
    "    on_unused_input='ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Do transformations per patient instead?\n",
    "if 'paired_transfos' in model_data:\n",
    "    paired_transfos = model_data['paired_transfos']\n",
    "else:\n",
    "    paired_transfos = False\n",
    "    \n",
    "print paired_transfos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to test on some train images, so loading the training set labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = p.read_csv(os.path.join('/srv/scratch/avanti/diabetic_retinopathy/trainLabels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_to_label = dict(zip(train_labels.image, train_labels.level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_dataloader_params = model_data['data_loader_params']\n",
    "train_image_ids = set(new_dataloader_params['images_train_0'])\n",
    "# Get validation set ids\n",
    "all_patient_ids = sorted(set(get_img_ids_from_iter(train_labels.image)))\n",
    "valid_patient_ids = [patient_id for patient_id in all_patient_ids\n",
    "                     if patient_id not in train_image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_patient_ids_labels = [image_to_label[str(patient_id)+\"_\"+side]\n",
    "                            for patient_id in valid_patient_ids\n",
    "                            for side in [\"left\",\"right\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_labels_fh = open(\"valid_labels.txt\",'w')\n",
    "for patient_id in valid_patient_ids:\n",
    "    for side in [\"left\", \"right\"]:\n",
    "        patient_id_and_side = str(patient_id)+\"_\"+side\n",
    "        valid_labels_fh.write(\n",
    "            patient_id_and_side+\"\\t\"+\n",
    "            \"\\t\".join(str(image_to_label[patient_id_and_side])+\"\\n\"))\n",
    "valid_labels_fh.close()\n",
    "!gzip valid_labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_chunks = int(np.ceil((2 * len(valid_patient_ids)) / float(chunk_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Where all the images are located: \n",
    "# it looks for [img_dir]/[patient_id]_[left or right].jpeg\n",
    "img_dir = '/srv/scratch/avanti/diabetic_retinopathy/unzipped_train_ds2_crop/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the DataLoader to set up the parameters, you could replace it with something much simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from generators import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader()\n",
    "#new_dataloader_params.update({'images_test': patient_ids})\n",
    "#new_dataloader_params.update({'labels_test': train_labels.level.values})\n",
    "new_dataloader_params.update({'prefix_train': img_dir})\n",
    "data_loader.set_params(new_dataloader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_pred(test_gen, deterministic):\n",
    "    outputs = []\n",
    "\n",
    "    for e, (xs_chunk, chunk_shape, chunk_length) in enumerate(test_gen()):\n",
    "        num_batches_chunk = int(np.ceil(chunk_length / float(batch_size)))\n",
    "\n",
    "        print \"Chunk %i/%i\" % (e + 1, num_chunks)\n",
    "\n",
    "        print \"  load data onto GPU\"\n",
    "        for x_shared, x_chunk in zip(xs_shared, xs_chunk):\n",
    "            x_shared.set_value(x_chunk)\n",
    "\n",
    "        print \"  compute output in batches\"\n",
    "        outputs_chunk = []\n",
    "        for b in xrange(num_batches_chunk):\n",
    "            if (deterministic):\n",
    "                out = compute_output(b)\n",
    "            else:\n",
    "                out = compute_nondeterministic_output(b)\n",
    "            outputs_chunk.append(out)\n",
    "\n",
    "        outputs_chunk = np.vstack(outputs_chunk)\n",
    "        outputs_chunk = outputs_chunk[:chunk_length]\n",
    "\n",
    "        outputs.append(outputs_chunk)\n",
    "\n",
    "    return np.vstack(outputs), xs_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.p_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from generators import patches_gen_fixed_pairs\n",
    "\n",
    "\n",
    "def create_fixed_gen(data_loader, images, chunk_size,\n",
    "                     prefix_train, prefix_test,\n",
    "                     transfo_params=None,\n",
    "                     paired_transfos=paired_transfos):\n",
    "\n",
    "    if not transfo_params:\n",
    "        raise ValueError(\"Need transfo_params for gen!\")\n",
    "\n",
    "    gen = patches_gen_fixed_pairs(\n",
    "            images, p_x=data_loader.p_x,\n",
    "            p_y=data_loader.p_y,\n",
    "            num_channels=data_loader.num_channels,\n",
    "            chunk_size=chunk_size,\n",
    "            prefix_train=prefix_train,\n",
    "            prefix_test=prefix_test,\n",
    "            transfo_params=transfo_params,\n",
    "            paired_transfos=paired_transfos)\n",
    "\n",
    "    def fixed_gen():\n",
    "        for chunk_x, chunk_dim, chunk_shape, chunk_length in gen:\n",
    "            yield [(chunk_x - data_loader.zmuv_mean) /\n",
    "                   (0.05 + data_loader.zmuv_std),\n",
    "                   chunk_dim], chunk_shape, chunk_length\n",
    "    return fixed_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing deterministic predictions\n"
     ]
    }
   ],
   "source": [
    "no_transfo_params = model_data['data_loader_params']['no_transfo_params']\n",
    "\n",
    "transfo_param_sets = [\n",
    "    {'flip': False,\n",
    "     'rotation_before_resize': True,\n",
    "     'rotation_range': (0,1)},\n",
    "    {'flip': True,\n",
    "     'flip_prob': 1.0,\n",
    "     'rotation_before_resize': True,\n",
    "     'rotation_range': (0,1)},\n",
    "    {'flip': False,\n",
    "     'rotation_before_resize': True,\n",
    "     'rotation_range': (90,91)},\n",
    "    {'flip': True,\n",
    "     'flip_prob': 1.0,\n",
    "     'rotation_before_resize': True,\n",
    "     'rotation_range': (90,91)},\n",
    "    {'flip': False,\n",
    "     'rotation_before_resize': True,\n",
    "     'rotation_range': (180,181)},\n",
    "    {'flip': True,\n",
    "     'flip_prob': 1.0,\n",
    "     'rotation_before_resize': True,\n",
    "     'rotation_range': (180,181)},\n",
    "    {'flip': False,\n",
    "     'rotation_before_resize': True,\n",
    "     'rotation_range': (270,271)},\n",
    "    {'flip': True,\n",
    "     'flip_prob': 1.0,\n",
    "     'rotation_before_resize': True,\n",
    "     'rotation_range': (270,271)},\n",
    "]\n",
    "\n",
    "def print_predictions(output_fh, pred_outputs, patient_ids):\n",
    "    for i,patient_id in enumerate(patient_ids):\n",
    "        for side in ['left', 'right']:\n",
    "            if (side=='left'):\n",
    "                pred = pred_outputs[i*2]\n",
    "            else:\n",
    "                pred = pred_outputs[i*2 + 1]\n",
    "            output_fh.write(str(patient_id)+\"_\"+side+\"\\t\"\n",
    "                            +\"\\t\".join([str(x) for x in pred])+\"\\n\")\n",
    "\n",
    "for transfo_params in transfo_param_sets:\n",
    "    transfo_string_summary = (\n",
    "        \"flip-\"+str(transfo_params['flip'])\n",
    "        +\"_rotamt-\"+str(transfo_params['rotation_range'][0]))\n",
    "    #transfo_string_summary=\"notransfo\"\n",
    "    if (os.path.exists(transfo_string_summary)==False):\n",
    "        os.mkdir(transfo_string_summary)\n",
    "    full_transfo_params = {}\n",
    "    full_transfo_params.update(no_transfo_params)\n",
    "    data_generator = lambda: create_fixed_gen(\n",
    "                        data_loader=data_loader,\n",
    "                        images=valid_patient_ids,\n",
    "                        chunk_size=chunk_size,\n",
    "                        prefix_train=img_dir,\n",
    "                        prefix_test=img_dir,\n",
    "                        transfo_params=full_transfo_params,\n",
    "                        paired_transfos=paired_transfos)\n",
    "    print(\"Doing deterministic predictions\")\n",
    "    sys.stdout.flush()\n",
    "    pred_outputs, chunk_orig = do_pred(test_gen=data_generator,\n",
    "                                       deterministic=True)\n",
    "    output_file = transfo_string_summary+\"/deterministic_preds.txt\"\n",
    "    output_fh = open(output_file,'w')\n",
    "    print_predictions(output_fh=output_fh,\n",
    "                      pred_outputs=pred_outputs,\n",
    "                      patient_ids=valid_patient_ids)\n",
    "    output_fh.close()\n",
    "    for nondeterministic_run in range(100):\n",
    "        print(\"nondet run\",nondeterministic_run)\n",
    "        sys.stdout.flush()\n",
    "        pred_outputs, chunk_orig = do_pred(test_gen=data_generator,\n",
    "                                           deterministic=False)\n",
    "        output_file = (transfo_string_summary+\n",
    "                       \"/nondeterministic_preds_\"\n",
    "                       +str(nondeterministic_run)+\".txt\")\n",
    "        output_fh = open(output_file,'w')\n",
    "        print_predictions(output_fh=output_fh,\n",
    "                          pred_outputs=pred_outputs,\n",
    "                          patient_ids=valid_patient_ids)\n",
    "        output_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can get some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 2/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 3/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 4/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 5/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 6/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 7/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 8/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 9/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 10/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 11/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 12/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 13/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "Chunk 14/14\n",
      "  load data onto GPU\n",
      "  compute output in batches\n",
      "CPU times: user 3min 38s, sys: 23.9 s, total: 4min 2s\n",
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs_orig, chunk_orig = do_pred(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore some of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9113879157475888\n",
      "0.8729840774273611\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "prob_disease = 1-outputs_orig[:,0]\n",
    "is_diseased = np.array([1 if x > 0 else 0\n",
    "                        for x in valid_patient_ids_labels])\n",
    "print(roc_auc_score(y_true=is_diseased,\n",
    "                    y_score=prob_disease))\n",
    "print(average_precision_score(y_true=is_diseased,\n",
    "                              y_score=prob_disease))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from metrics import continuous_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa 0.8277 \n",
      "\n",
      "[[2473  151   95    4    3]\n",
      " [  42   51   29    0    0]\n",
      " [  52   46  293   18    9]\n",
      " [   0    0  109   58   17]\n",
      " [   2    0   10    6   46]] \n",
      "\n",
      "[[ 0.     9.438 23.75   2.25   3.   ]\n",
      " [ 2.625  0.     1.812  0.     0.   ]\n",
      " [13.     2.875  0.     1.125  2.25 ]\n",
      " [ 0.     0.     6.812  0.     1.062]\n",
      " [ 2.     0.     2.5    0.375  0.   ]] \n",
      "\n",
      "[[0.    0.126 0.317 0.03  0.04 ]\n",
      " [0.035 0.    0.024 0.    0.   ]\n",
      " [0.174 0.038 0.    0.015 0.03 ]\n",
      " [0.    0.    0.091 0.    0.014]\n",
      " [0.027 0.    0.033 0.005 0.   ]] 74.875\n"
     ]
    }
   ],
   "source": [
    "outputs_labels = np.argmax(outputs_orig, axis=1)\n",
    "\n",
    "kappa_eval = continuous_kappa(\n",
    "                outputs_labels,\n",
    "                np.array(valid_patient_ids_labels))\n",
    "\n",
    "metric, conf_mat, \\\n",
    "    hist_rater_a, hist_rater_b, \\\n",
    "    nom, denom = kappa_eval\n",
    "    \n",
    "print 'Kappa %.4f' % metric, '\\n'\n",
    "print conf_mat, '\\n'\n",
    "print nom, '\\n'\n",
    "print nom / nom.sum(), nom.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
