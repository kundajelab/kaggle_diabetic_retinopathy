{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "valid_labels = LabelBinarizer().fit_transform(\n",
    "    np.array([float(x.decode(\"utf-8\").split(\"\\t\")[1])\n",
    "              for x in gzip.open(\"valid_labels.txt.gz\",'rb')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#augmenting the dataset with flips and rotaitons, for more robustness\n",
    "parent_folders = [\"flip-False_rotamt-0\",\n",
    "                  \"flip-True_rotamt-0\",\n",
    "                  \"flip-False_rotamt-90\",\n",
    "                  \"flip-True_rotamt-90\",\n",
    "                  \"flip-False_rotamt-180\",\n",
    "                  \"flip-True_rotamt-180\",\n",
    "                  \"flip-False_rotamt-270\",\n",
    "                  \"flip-True_rotamt-270\",]\n",
    "\n",
    "parent_folder_to_det_pred = {}\n",
    "for parent_folder in parent_folders:\n",
    "    det_preds = np.array([\n",
    "            [float(y) for y in x.decode(\"utf-8\").split(\"\\t\")[1:]]\n",
    "             for x in gzip.open(parent_folder+\"/deterministic_preds.txt.gz\", 'rb')])\n",
    "    parent_folder_to_det_pred[parent_folder] = det_preds\n",
    "    \n",
    "parent_folder_to_nondet_pred = {}\n",
    "parent_folder_to_mean_nondet_pred = {}\n",
    "for parent_folder in parent_folders:\n",
    "    nondet_preds = []\n",
    "    for i in range(100):\n",
    "        single_nondet_pred = np.array([\n",
    "            [float(y) for y in x.decode(\"utf-8\").split(\"\\t\")[1:]]\n",
    "             for x in gzip.open(\n",
    "              parent_folder+\"/nondeterministic_preds_\"+str(i)+\".txt.gz\", 'rb')])\n",
    "        nondet_preds.append(single_nondet_pred)\n",
    "    nondet_preds = np.array(nondet_preds)\n",
    "    parent_folder_to_nondet_pred[parent_folder] = nondet_preds\n",
    "    parent_folder_to_mean_nondet_pred[parent_folder] = np.mean(nondet_preds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip-False_rotamt-0\n",
      "deterministic pred auROC 0.9118638796723656\n",
      "nondeterministic pred auROC 0.9129881925522253\n",
      "flip-True_rotamt-0\n",
      "deterministic pred auROC 0.9136845292158645\n",
      "nondeterministic pred auROC 0.9141930341618936\n",
      "flip-False_rotamt-90\n",
      "deterministic pred auROC 0.9077797755493358\n",
      "nondeterministic pred auROC 0.9079080860318696\n",
      "flip-True_rotamt-90\n",
      "deterministic pred auROC 0.9072243126739039\n",
      "nondeterministic pred auROC 0.9084814670645733\n",
      "flip-False_rotamt-180\n",
      "deterministic pred auROC 0.916166708887612\n",
      "nondeterministic pred auROC 0.9166587373671843\n",
      "flip-True_rotamt-180\n",
      "deterministic pred auROC 0.9131712872857287\n",
      "nondeterministic pred auROC 0.9138490879246036\n",
      "flip-False_rotamt-270\n",
      "deterministic pred auROC 0.9074450973244279\n",
      "nondeterministic pred auROC 0.9075221248051144\n",
      "flip-True_rotamt-270\n",
      "deterministic pred auROC 0.9051834963473733\n",
      "nondeterministic pred auROC 0.9063560028916199\n"
     ]
    }
   ],
   "source": [
    "#Compute the auROC/auPRC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for parent_folder in parent_folders:\n",
    "    print(parent_folder)\n",
    "    det_preds = parent_folder_to_det_pred[parent_folder]\n",
    "    mean_nondet_preds = parent_folder_to_mean_nondet_pred[parent_folder]\n",
    "    print(\"deterministic pred auROC\",\n",
    "          roc_auc_score(y_true=1-valid_labels[:,0],\n",
    "                              y_score=1-det_preds[:,0]))\n",
    "    print(\"nondeterministic pred auROC\",\n",
    "          roc_auc_score(y_true=1-valid_labels[:,0],\n",
    "                              y_score=1-mean_nondet_preds[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstainer settings calib_weightrescalepreds_imbalanced_adapted\n",
      "on fold 0\n",
      "[10280   992  2144   336   296]\n",
      "valid vs. test distribution shift Valid dist: [0.73177677 0.07061503 0.15261959 0.023918   0.02107062] Test dist: [0.91371642 0.05515033 0.02383917 0.00391389 0.00338018]\n",
      "Distribution shift from true labels after calibration: True: [0.73177677 0.07061503 0.15261959 0.023918   0.02107062] Estimated: [0.70398613 0.1021053  0.11840535 0.05697056 0.01853267] Difference: [ 0.02779063 -0.03149026  0.03421424 -0.03305256  0.00253795]\n",
      "Original class imbalance [0.70398613 0.1021053  0.11840535 0.05697056 0.01853267]\n",
      "Finished on iteration 8 with delta 0.0020559468131290566\n",
      "Final imbalance [0.88337398 0.0741724  0.03079887 0.0055813  0.00607346]\n",
      "Multiplier: [1.2548173  0.72643046 0.26011385 0.09796807 0.32771641]\n",
      "Accuracy before adaptation: 0.9042874933285893\n",
      "WKappa before adaptation: 0.6467983358357531\n",
      "Accuracy after adaptation: 0.9162960327343889\n",
      "WKappa after adaptation: 0.6794150406334958\n",
      "on fold 1\n",
      "[10280   992  2136   336   304]\n",
      "valid vs. test distribution shift Valid dist: [0.73177677 0.07061503 0.15205011 0.023918   0.02164009] Test dist: [0.91371642 0.05515033 0.02392813 0.00391389 0.00329123]\n",
      "Distribution shift from true labels after calibration: True: [0.73177677 0.07061503 0.15205011 0.023918   0.02164009] Estimated: [0.69987464 0.10334904 0.12173925 0.05460899 0.02042808] Difference: [ 0.03190212 -0.03273401  0.03031087 -0.03069099  0.00121201]\n",
      "Original class imbalance [0.69987464 0.10334904 0.12173925 0.05460899 0.02042808]\n",
      "Finished on iteration 8 with delta 0.002335316796993333\n",
      "Final imbalance [0.89284273 0.07030682 0.02271152 0.00967127 0.00446766]\n",
      "Multiplier: [1.27571807 0.68028513 0.18655873 0.17710038 0.21870182]\n",
      "Accuracy before adaptation: 0.9134495641344956\n",
      "WKappa before adaptation: 0.6984021000037309\n",
      "Accuracy after adaptation: 0.9235901085216154\n",
      "WKappa after adaptation: 0.7348968956541244\n",
      "on fold 2\n",
      "[10272   984  2144   336   296]\n",
      "valid vs. test distribution shift Valid dist: [0.73204105 0.07012543 0.15279361 0.02394527 0.02109464] Test dist: [0.91337183 0.05553088 0.02381164 0.00390937 0.00337628]\n",
      "Distribution shift from true labels after calibration: True: [0.73204105 0.07012543 0.15279361 0.02394527 0.02109464] Estimated: [0.70555541 0.10554822 0.11742166 0.05374616 0.01772856] Difference: [ 0.02648564 -0.03542279  0.03537196 -0.02980089  0.00336608]\n",
      "Original class imbalance [0.70555541 0.10554822 0.11742166 0.05374616 0.01772856]\n",
      "Finished on iteration 11 with delta 0.002061107624596709\n",
      "Final imbalance [0.88881098 0.06437222 0.03314678 0.00713643 0.00653358]\n",
      "Multiplier: [1.25973236 0.60988448 0.28228851 0.13278037 0.36853425]\n",
      "Accuracy before adaptation: 0.9123944913371834\n",
      "WKappa before adaptation: 0.6891483873770146\n",
      "Accuracy after adaptation: 0.9240337627721013\n",
      "WKappa after adaptation: 0.7244807859497363\n",
      "on fold 3\n",
      "[10280   992  2144   336   296]\n",
      "valid vs. test distribution shift Valid dist: [0.73177677 0.07061503 0.15261959 0.023918   0.02107062] Test dist: [0.91371642 0.05515033 0.02383917 0.00391389 0.00338018]\n",
      "Distribution shift from true labels after calibration: True: [0.73177677 0.07061503 0.15261959 0.023918   0.02107062] Estimated: [0.70413407 0.10526727 0.11394911 0.0568224  0.01982714] Difference: [ 0.0276427  -0.03465224  0.03867048 -0.03290441  0.00124347]\n",
      "Original class imbalance [0.70413407 0.10526727 0.11394911 0.0568224  0.01982714]\n",
      "Finished on iteration 5 with delta 0.0026586735791563074\n",
      "Final imbalance [0.85334884 0.0999536  0.03570904 0.00551657 0.00547195]\n",
      "Multiplier: [1.21191245 0.94952208 0.31337705 0.09708437 0.27598301]\n",
      "Accuracy before adaptation: 0.912026329834549\n",
      "WKappa before adaptation: 0.6874012421137264\n",
      "Accuracy after adaptation: 0.9211884006404555\n",
      "WKappa after adaptation: 0.7127548591326953\n",
      "on fold 4\n",
      "[10280   992  2144   336   296]\n",
      "valid vs. test distribution shift Valid dist: [0.73177677 0.07061503 0.15261959 0.023918   0.02107062] Test dist: [0.91371642 0.05515033 0.02383917 0.00391389 0.00338018]\n",
      "Distribution shift from true labels after calibration: True: [0.73177677 0.07061503 0.15261959 0.023918   0.02107062] Estimated: [0.70693229 0.09836886 0.11767594 0.05855578 0.01846713] Difference: [ 0.02484448 -0.02775382  0.03494365 -0.03463779  0.00260348]\n",
      "Original class imbalance [0.70693229 0.09836886 0.11767594 0.05855578 0.01846713]\n",
      "Finished on iteration 9 with delta 0.0019756728995874457\n",
      "Final imbalance [0.85958092 0.10228131 0.0282437  0.00496802 0.00492604]\n",
      "Multiplier: [1.21593106 1.03977331 0.24001252 0.08484257 0.26674642]\n",
      "Accuracy before adaptation: 0.9049991104785625\n",
      "WKappa before adaptation: 0.6740599195369246\n",
      "Accuracy after adaptation: 0.9161181284468956\n",
      "WKappa after adaptation: 0.7162410423661276\n",
      "on fold 5\n",
      "[10280   992  2136   336   304]\n",
      "valid vs. test distribution shift"
     ]
    }
   ],
   "source": [
    "import abstention\n",
    "reload(abstention.abstention)\n",
    "reload(abstention.calibration)\n",
    "from abstention.calibration import (compute_ece, TempScaling,\n",
    "                                    EMImbalanceAdapter)\n",
    "from abstention.abstention import (weighted_kappa_metric,\n",
    "                                   WeightedKappa, DistMaxClassProbFromOne,\n",
    "                                   Entropy, Uncertainty)\n",
    "from collections import defaultdict, namedtuple\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def inverse_softmax(preds):\n",
    "    return np.log(preds) - np.mean(np.log(preds),axis=1)[:,None]\n",
    "\n",
    "quadratic_weights = np.array([[(i-j)**2 for i in range(5)]\n",
    "                             for j in range(5)])\n",
    "\n",
    "AbstainerSettings = namedtuple(\"AbstainerSettings\",\n",
    "                               [\"name\",\n",
    "                                \"abstainer_factories\",\n",
    "                                \"preds_lookup\",\n",
    "                                \"predsamples_lookup\",\n",
    "                                \"use_calib\",\n",
    "                                \"imbalance_subsampling\",\n",
    "                                \"imbalance_adapter\"])\n",
    "\n",
    "abstainer_factories = [\n",
    "        (\"expected_delta_weighted_kappa\", WeightedKappa(\n",
    "            weights=quadratic_weights, verbose=False)),\n",
    "        (\"expected_delta_weighted_kappa_imbalance_from_valid\", WeightedKappa(\n",
    "                weights=quadratic_weights,\n",
    "                estimate_class_imbalance_from_valid=True,\n",
    "                verbose=False)),\n",
    "        (\"dist_maxclass_prob_from_one\", DistMaxClassProbFromOne()),\n",
    "        (\"entropy\", Entropy()),\n",
    "        (\"variance\", Uncertainty())]\n",
    "abstention_fractions = [0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "abstainer_settings_list = [\n",
    "    AbstainerSettings(\n",
    "        name=\"calib_weightrescalepreds_imbalanced_adapted\",\n",
    "        abstainer_factories=abstainer_factories,\n",
    "        preds_lookup=parent_folder_to_det_pred,\n",
    "        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "        use_calib=True,\n",
    "        imbalance_subsampling=[8, 5, 1, 1, 1],\n",
    "        imbalance_adapter=EMImbalanceAdapter(verbose=True)),\n",
    "    AbstainerSettings(\n",
    "        name=\"calib_weightrescalepreds_imbalanced_unadapted\",\n",
    "        abstainer_factories=abstainer_factories,\n",
    "        preds_lookup=parent_folder_to_det_pred,\n",
    "        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "        use_calib=True,\n",
    "        imbalance_subsampling=[1.0, 0.8, 0.5, 0.2, 0.2],\n",
    "        imbalance_adapter=None),\n",
    "    AbstainerSettings(\n",
    "        name=\"calib_mcdrpreds_imbalanced_adapted\",\n",
    "        abstainer_factories=abstainer_factories,\n",
    "        preds_lookup=parent_folder_to_mean_nondet_pred,\n",
    "        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "        use_calib=True,\n",
    "        imbalance_subsampling=[1.0, 0.8, 0.5, 0.2, 0.2],\n",
    "        imbalance_adapter=EMImbalanceAdapter(verbose=False)),\n",
    "    AbstainerSettings(\n",
    "        name=\"calib_mcdrpreds_imbalanced_unadapted\",\n",
    "        abstainer_factories=abstainer_factories,\n",
    "        preds_lookup=parent_folder_to_mean_nondet_pred,\n",
    "        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "        use_calib=True,\n",
    "        imbalance_subsampling=[1.0, 0.8, 0.5, 0.2, 0.2],\n",
    "        imbalance_adapter=None),\n",
    "#    AbstainerSettings(\n",
    "#        name=\"calib_weightrescalepreds\",\n",
    "#        abstainer_factories=abstainer_factories,\n",
    "#        preds_lookup=parent_folder_to_det_pred,\n",
    "#        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "#        use_calib=True,\n",
    "#        imbalance_subsampling=None),  \n",
    "#    AbstainerSettings(\n",
    "#        name=\"uncalib_weightrescalepreds\",\n",
    "#        abstainer_factories=abstainer_factories,\n",
    "#        preds_lookup=parent_folder_to_det_pred,\n",
    "#        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "#        use_calib=False,\n",
    "#        imbalance_subsampling=None),\n",
    "#    AbstainerSettings(\n",
    "#        name=\"calib_mcdrpreds\",\n",
    "#        abstainer_factories=abstainer_factories,\n",
    "#        preds_lookup=parent_folder_to_mean_nondet_pred,\n",
    "#        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "#        use_calib=True,\n",
    "#        imbalance_subsampling=None),\n",
    "#    AbstainerSettings(\n",
    "#        name=\"uncalib_mcdrpreds\",\n",
    "#        abstainer_factories=abstainer_factories,\n",
    "#        preds_lookup=parent_folder_to_mean_nondet_pred,\n",
    "#        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "#        use_calib=False,\n",
    "#        imbalance_subsampling=None)\n",
    "]\n",
    "\n",
    "num_folds = 50\n",
    "\n",
    "settingsname_to_metric_to_fraction_to_method_to_perfs = {}\n",
    "settingsname_to_metric_to_baselineperfs = {}\n",
    "\n",
    "for abstainer_settings in abstainer_settings_list:\n",
    "    \n",
    "    settings_name = abstainer_settings.name\n",
    "    print(\"abstainer settings\", settings_name)\n",
    "    abstainer_factories = abstainer_settings.abstainer_factories\n",
    "    preds_lookup = abstainer_settings.preds_lookup\n",
    "    predsamples_lookup = abstainer_settings.predsamples_lookup\n",
    "    use_calib = abstainer_settings.use_calib\n",
    "    imbalance_subsampling = abstainer_settings.imbalance_subsampling\n",
    "    imbalance_adapter = abstainer_settings.imbalance_adapter\n",
    "    \n",
    "    metric_to_fraction_to_method_to_perfs =\\\n",
    "        defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    settingsname_to_metric_to_fraction_to_method_to_perfs[settings_name] =\\\n",
    "        metric_to_fraction_to_method_to_perfs\n",
    "    metric_to_baselineperfs = defaultdict(list)   \n",
    "    settingsname_to_metric_to_baselineperfs[settings_name] =\\\n",
    "        metric_to_baselineperfs\n",
    "    \n",
    "    for fold_number in range(num_folds):\n",
    "        print(\"on fold\",fold_number)\n",
    "\n",
    "        np.random.seed(fold_number*1000)\n",
    "        random.seed(fold_number*1000)\n",
    "        #the data is in pairs of (left eye, right eye) per patient (entry for\n",
    "        # the right eye comes after the entry for the left eye); hence, the number of\n",
    "        # unique patients is 0.5*len(valid_labels)\n",
    "        patient_id_ordering = list(range(int(0.5*len(valid_labels))))\n",
    "        np.random.shuffle(patient_id_ordering)\n",
    "\n",
    "        pseudovalid_uncalib_preds = []\n",
    "        pseudotest_uncalib_preds = []\n",
    "        pseudovalid_uncalib_predsamples = []\n",
    "        pseudotest_uncalib_predsamples = []\n",
    "        pseudovalid_labels = []\n",
    "        pseudotest_labels = []\n",
    "        pseudovalid_label_counts = np.zeros(5)\n",
    "        pseudotest_label_counts = np.zeros(5)\n",
    "        for i in patient_id_ordering:\n",
    "            left_eye_label = valid_labels[2*i]\n",
    "            right_eye_label = valid_labels[(2*i)+1]\n",
    "            most_diseased_label = max(np.argmax(left_eye_label),\n",
    "                                      np.argmax(right_eye_label))\n",
    "            if (pseudovalid_label_counts[most_diseased_label] <\n",
    "                pseudotest_label_counts[most_diseased_label]):\n",
    "                in_test = False\n",
    "                append_to_uncalib_preds = pseudovalid_uncalib_preds\n",
    "                append_to_uncalib_predsamples = pseudovalid_uncalib_predsamples\n",
    "                append_to_labels = pseudovalid_labels\n",
    "                append_to_label_counts = pseudovalid_label_counts\n",
    "            else:\n",
    "                in_test = True\n",
    "                append_to_uncalib_preds = pseudotest_uncalib_preds\n",
    "                append_to_uncalib_predsamples = pseudotest_uncalib_predsamples\n",
    "                append_to_labels = pseudotest_labels\n",
    "                append_to_label_counts = pseudotest_label_counts\n",
    "            \n",
    "            append_to_label_counts += valid_labels[2*i]\n",
    "            append_to_label_counts += valid_labels[(2*i)+1]\n",
    "            for parent_folder_idx,parent_folder in enumerate(parent_folders):\n",
    "                if ((not in_test) or\n",
    "                    imbalance_subsampling[np.argmax(valid_labels[2*i])] > parent_folder_idx):\n",
    "                    append_to_labels.append(valid_labels[2*i])\n",
    "                    append_to_uncalib_preds.append(\n",
    "                            preds_lookup[parent_folder][2*i])\n",
    "                    append_to_uncalib_predsamples.append(\n",
    "                        predsamples_lookup[parent_folder][:,(2*i)])                    \n",
    "                if ((not in_test) or\n",
    "                    imbalance_subsampling[np.argmax(valid_labels[(2*i) + 1])] > parent_folder_idx): \n",
    "                    append_to_labels.append(valid_labels[(2*i)+1])\n",
    "                    append_to_uncalib_preds.append(\n",
    "                        preds_lookup[parent_folder][(2*i)+1])\n",
    "                    append_to_uncalib_predsamples.append(\n",
    "                        predsamples_lookup[parent_folder][:,(2*i)+1])\n",
    "        print(np.sum(pseudovalid_labels,axis=0))\n",
    "                \n",
    "        pseudovalid_uncalib_preds = np.array(pseudovalid_uncalib_preds)\n",
    "        pseudotest_uncalib_preds = np.array(pseudotest_uncalib_preds)\n",
    "        pseudovalid_uncalib_pred_logits = inverse_softmax(pseudovalid_uncalib_preds)\n",
    "        pseudotest_uncalib_pred_logits = inverse_softmax(pseudotest_uncalib_preds)\n",
    "        pseudovalid_uncalib_predsamples = np.array(pseudovalid_uncalib_predsamples).transpose((1,0,2))\n",
    "        pseudotest_uncalib_predsamples = np.array(pseudotest_uncalib_predsamples).transpose((1,0,2))\n",
    "        pseudovalid_uncalib_predsamples_logits = np.array([\n",
    "                inverse_softmax(x) for x in pseudovalid_uncalib_predsamples])        \n",
    "        pseudotest_uncalib_predsamples_logits = np.array([\n",
    "                inverse_softmax(x) for x in pseudotest_uncalib_predsamples])\n",
    "        pseudovalid_labels = np.array(pseudovalid_labels) \n",
    "        pseudotest_labels = np.array(pseudotest_labels)\n",
    "        print(\"valid vs. test distribution shift\",\n",
    "              \"Valid dist:\",np.mean(pseudovalid_labels,axis=0),\n",
    "              \"Test dist:\",np.mean(pseudotest_labels,axis=0))\n",
    "        \n",
    "        if (use_calib):\n",
    "            #print(\"ece before temp scale - valid\",\n",
    "            #  compute_ece(softmax_out=pseudovalid_uncalib_preds,\n",
    "            #              labels=pseudovalid_labels,\n",
    "            #              bins=15))\n",
    "            #print(\"ece before temp scale - test\",\n",
    "            #      compute_ece(softmax_out=pseudotest_uncalib_preds,\n",
    "            #                  labels=pseudotest_labels,\n",
    "            #                  bins=15))\n",
    "            temp_scaler = TempScaling(ece_bins=15, verbose=False)(\n",
    "                                valid_preacts=pseudovalid_uncalib_pred_logits,\n",
    "                                valid_labels=pseudovalid_labels)\n",
    "            pseudovalid_calib_preds = temp_scaler(pseudovalid_uncalib_pred_logits)\n",
    "            pseudotest_calib_preds = temp_scaler(pseudotest_uncalib_pred_logits)\n",
    "            print(\"Distribution shift from true labels after calibration:\",\n",
    "                  \"True:\",np.mean(pseudovalid_labels,axis=0),\n",
    "                  \"Estimated:\",np.mean(pseudovalid_calib_preds,axis=0),\n",
    "                  \"Difference:\", np.mean(pseudovalid_labels-pseudovalid_calib_preds,\n",
    "                                         axis=0))\n",
    "            pseudovalid_calib_predsamples = np.array(\n",
    "                [temp_scaler(x) for x in pseudovalid_uncalib_predsamples_logits])\n",
    "            pseudotest_calib_predsamples = np.array(\n",
    "                [temp_scaler(x) for x in pseudotest_uncalib_predsamples_logits])       \n",
    "            #print(\"ece after temp scale - valid\",\n",
    "            #      compute_ece(softmax_out=pseudovalid_calib_preds,\n",
    "            #            labels=pseudovalid_labels,\n",
    "            #            bins=15))\n",
    "            #print(\"ece after temp scale - test\",\n",
    "            #      compute_ece(softmax_out=pseudotest_calib_preds,\n",
    "            #            labels=pseudotest_labels,\n",
    "            #            bins=15))\n",
    "            \n",
    "        if (use_calib):\n",
    "            pseudotest_preds_to_use=pseudotest_calib_preds\n",
    "            pseudovalid_preds_to_use=pseudovalid_calib_preds\n",
    "            pseudotest_predsamples_to_use=pseudotest_calib_predsamples\n",
    "            pseudovalid_predsamples_to_use=pseudovalid_calib_predsamples\n",
    "        else:\n",
    "            pseudotest_preds_to_use=pseudotest_uncalib_preds\n",
    "            pseudovalid_preds_to_use=pseudovalid_uncalib_preds\n",
    "            pseudotest_predsamples_to_use=pseudotest_uncalib_predsamples\n",
    "            pseudovalid_predsamples_to_use=pseudovalid_uncalib_predsamples\n",
    "        \n",
    "        if (imbalance_adapter is not None):\n",
    "            imbalance_adaptation_func = imbalance_adapter(\n",
    "                #set the validation labels to be pseudovalid_preds_to_use\n",
    "                # (rather than pseudovalid_labels) for consistency;\n",
    "                # we want no adjustment to happen in the\n",
    "                # case where tofit_initial_posterior_probs=pseudovalid_preds_to_use\n",
    "                valid_labels=pseudovalid_preds_to_use,\n",
    "                tofit_initial_posterior_probs=pseudotest_preds_to_use)\n",
    "            preds_before_adaptation = pseudotest_preds_to_use\n",
    "            pseudotest_preds_to_use = imbalance_adaptation_func(pseudotest_preds_to_use)\n",
    "            print(\"Accuracy before adaptation:\",\n",
    "                  np.mean(np.argmax(preds_before_adaptation,axis=-1)\n",
    "                          ==np.argmax(pseudotest_labels,axis=-1)))\n",
    "            print(\"WKappa before adaptation:\",\n",
    "                  weighted_kappa_metric(\n",
    "                        predprobs=preds_before_adaptation,\n",
    "                        true_labels=pseudotest_labels,\n",
    "                        weights=quadratic_weights))\n",
    "            print(\"Accuracy after adaptation:\",\n",
    "                  np.mean(np.argmax(pseudotest_preds_to_use,axis=-1)\n",
    "                          ==np.argmax(pseudotest_labels,axis=-1)))\n",
    "            print(\"WKappa after adaptation:\",\n",
    "                  weighted_kappa_metric(\n",
    "                        predprobs=pseudotest_preds_to_use,\n",
    "                        true_labels=pseudotest_labels,\n",
    "                        weights=quadratic_weights))\n",
    "            #print((zip(preds_before_adaptation,pseudotest_preds_to_use))[:20])\n",
    "            \n",
    "            #print(\"Difference from true imbalance\",\n",
    "            #      np.mean(pseudotest_preds_to_use,axis=0)-\n",
    "            #      np.mean(pseudotest_labels,axis=0))\n",
    "            pseudotest_predsamples_to_use = np.array([\n",
    "                    imbalance_adaptation_func(x) for\n",
    "                    x in pseudotest_predsamples_to_use])\n",
    "\n",
    "        pseudovalid_variance_to_use = np.sum(np.var(pseudovalid_predsamples_to_use, axis=0),\n",
    "                                             axis=-1)\n",
    "        pseudotest_variance_to_use = np.sum(np.var(pseudotest_predsamples_to_use, axis=0),\n",
    "                                            axis=-1)\n",
    "            \n",
    "        original_weighted_kappa_perf = weighted_kappa_metric(\n",
    "            predprobs=pseudotest_preds_to_use,\n",
    "            true_labels=pseudotest_labels,\n",
    "            weights=quadratic_weights)\n",
    "        \n",
    "        #print(\"\\nPseudotest set weighted kappa\",\n",
    "        #      original_weighted_kappa_perf)\n",
    "        metric_to_baselineperfs[\"weighted_kappa\"].append(\n",
    "            original_weighted_kappa_perf)\n",
    "        original_accuracy_perf = np.mean(\n",
    "            np.argmax(pseudotest_preds_to_use,axis=-1)\n",
    "            ==np.argmax(pseudotest_labels,axis=-1))\n",
    "        #print(\"Pseudotest set accuracy\",original_accuracy_perf)\n",
    "        metric_to_baselineperfs[\"accuracy\"].append(original_accuracy_perf)\n",
    "        \n",
    "        for abstention_fraction in abstention_fractions:\n",
    "            #print(\"\\nabstention fraction:\",abstention_fraction)\n",
    "            for abstainer_name, abstainer_factory in abstainer_factories:\n",
    "                abstainer = abstainer_factory(\n",
    "                    valid_labels=pseudovalid_labels,\n",
    "                    valid_posterior=pseudovalid_preds_to_use)\n",
    "                abstainer_priorities = abstainer(\n",
    "                    posterior_probs=pseudotest_preds_to_use,\n",
    "                    uncertainties=pseudotest_variance_to_use)\n",
    "                indices_to_retain = (\n",
    "                    [y[0] for y in sorted(enumerate(abstainer_priorities),\n",
    "                        key=lambda x: x[1])][:int(len(abstainer_priorities)*\n",
    "                                                     (1-abstention_fraction))])\n",
    "                retained_pseudotest_preds = np.array(\n",
    "                    [pseudotest_preds_to_use[i] for i in indices_to_retain])\n",
    "                retained_pseudotest_labels = np.array(\n",
    "                    [pseudotest_labels[i] for i in indices_to_retain])\n",
    "                #print(\"\\nAbstention criterion:\",abstainer_name)\n",
    "                weighted_kappa_perf = weighted_kappa_metric(\n",
    "                    predprobs=retained_pseudotest_preds,\n",
    "                    true_labels=retained_pseudotest_labels,\n",
    "                    weights=quadratic_weights)\n",
    "                #print(\"weighted kappa\", weighted_kappa_perf)\n",
    "                accuracy_perf = (np.mean(np.argmax(\n",
    "                    retained_pseudotest_preds,axis=-1)\n",
    "                    ==np.argmax(retained_pseudotest_labels,axis=-1)))\n",
    "                #print(\"accuracy\", accuracy_perf)\n",
    "\n",
    "                metric_to_fraction_to_method_to_perfs[\"delta_weighted_kappa\"][\n",
    "                    abstention_fraction][abstainer_name].append(\n",
    "                        weighted_kappa_perf-original_weighted_kappa_perf)\n",
    "                metric_to_fraction_to_method_to_perfs[\"delta_accuracy\"][\n",
    "                    abstention_fraction][abstainer_name].append(\n",
    "                        accuracy_perf-original_accuracy_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "fh = open(\"imbalanced_abstention_results.json\", 'w')\n",
    "fh.write(json.dumps({\n",
    "            \"settingsname_to_metric_to_fraction_to_method_to_perfs\":\n",
    "              settingsname_to_metric_to_fraction_to_method_to_perfs,\n",
    "            \"settingsname_to_metric_to_baselineperfs\":\n",
    "              settingsname_to_metric_to_baselineperfs},\n",
    "             sort_keys=True,\n",
    "             indent=4,\n",
    "             separators=(',', ': ')))\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "loaded_data = json.loads(open(\"balanced_abstention_results.json\").read())\n",
    "settingsname_to_metric_to_fraction_to_method_to_perfs.update(\n",
    "    loaded_data[\"settingsname_to_metric_to_fraction_to_method_to_perfs\"])\n",
    "settingsname_to_metric_to_baselineperfs.update(\n",
    "    loaded_data[\"settingsname_to_metric_to_baselineperfs\"])\n",
    "\n",
    "import json\n",
    "fh = open(\"abstention_results.json\", 'w')\n",
    "fh.write(json.dumps({\n",
    "            \"settingsname_to_metric_to_fraction_to_method_to_perfs\":\n",
    "              settingsname_to_metric_to_fraction_to_method_to_perfs,\n",
    "            \"settingsname_to_metric_to_baselineperfs\":\n",
    "              settingsname_to_metric_to_baselineperfs},\n",
    "             sort_keys=True,\n",
    "             indent=4,\n",
    "             separators=(',', ': ')))\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "loaded_data = json.loads(open(\"abstention_results.json\").read())\n",
    "settingsname_to_metric_to_fraction_to_method_to_perfs =\\\n",
    "    loaded_data[\"settingsname_to_metric_to_fraction_to_method_to_perfs\"]\n",
    "settingsname_to_metric_to_baselineperfs =\\\n",
    "    loaded_data[\"settingsname_to_metric_to_baselineperfs\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from abstention.figure_making_utils import (\n",
    "    wilcox_srs, get_ustats_mat,\n",
    "    get_tied_top_and_worst_methods)\n",
    "from collections import OrderedDict\n",
    "\n",
    "comparison_groups = OrderedDict([\n",
    "        ('Imbalanced, with weight rescaling', ([\n",
    "          ('calib_weightrescalepreds_imbalanced_adapted', 'expected_delta_weighted_kappa'),\n",
    "          ('calib_weightrescalepreds_imbalanced_unadapted', 'expected_delta_weighted_kappa'),\n",
    "          ('calib_weightrescalepreds_imbalanced_adapted', 'dist_maxclass_prob_from_one'),\n",
    "          ('calib_weightrescalepreds_imbalanced_unadapted', 'dist_maxclass_prob_from_one'),\n",
    "          ('calib_weightrescalepreds_imbalanced_adapted', 'entropy'),\n",
    "          ('calib_weightrescalepreds_imbalanced_unadapted', 'entropy'),\n",
    "          ('calib_weightrescalepreds_imbalanced_adapted', 'variance'),\n",
    "          ('calib_weightrescalepreds_imbalanced_unadapted', 'variance')],\n",
    "         ['adapted'])),\n",
    "        ('Balanced, with weight rescaling', ([\n",
    "          ('calib_weightrescalepreds', 'expected_delta_weighted_kappa'),\n",
    "          ('uncalib_weightrescalepreds', 'expected_delta_weighted_kappa'),\n",
    "          ('calib_weightrescalepreds', 'dist_maxclass_prob_from_one'),\n",
    "          ('uncalib_weightrescalepreds', 'dist_maxclass_prob_from_one'),\n",
    "          ('calib_weightrescalepreds', 'entropy'),\n",
    "          ('uncalib_weightrescalepreds', 'entropy'),\n",
    "          ('calib_weightrescalepreds', 'variance'),\n",
    "          ('uncalib_weightrescalepreds', 'variance')],\n",
    "         ['calib'])),\n",
    "       ('Imalanced, with MC dropout', ([\n",
    "          ('calib_mcdrpreds_imbalanced_adapted', 'expected_delta_weighted_kappa'),\n",
    "          ('calib_mcdrpreds_imbalanced_unadapted', 'expected_delta_weighted_kappa'),\n",
    "          ('calib_mcdrpreds_imbalanced_adapted', 'dist_maxclass_prob_from_one'),\n",
    "          ('calib_mcdrpreds_imbalanced_unadapted', 'dist_maxclass_prob_from_one'),\n",
    "          ('calib_mcdrpreds_imbalanced_adapted', 'entropy'),\n",
    "          ('calib_mcdrpreds_imbalanced_unadapted', 'entropy'),\n",
    "          ('calib_mcdrpreds_imbalanced_adapted', 'variance'),\n",
    "          ('calib_mcdrpreds_imbalanced_unadapted', 'variance')],\n",
    "         ['adapted'])),\n",
    "       ('Balanced, with MC dropout', ([\n",
    "          ('calib_mcdrpreds', 'expected_delta_weighted_kappa'),\n",
    "          ('uncalib_mcdrpreds', 'expected_delta_weighted_kappa'),\n",
    "          ('calib_mcdrpreds', 'dist_maxclass_prob_from_one'),\n",
    "          ('uncalib_mcdrpreds', 'dist_maxclass_prob_from_one'),\n",
    "          ('calib_mcdrpreds', 'entropy'),\n",
    "          ('uncalib_mcdrpreds', 'entropy'),\n",
    "          ('calib_mcdrpreds', 'variance'),\n",
    "          ('uncalib_mcdrpreds', 'variance')],\n",
    "         ['calib']))\n",
    "    ])\n",
    "\n",
    "friendly_method_names = {\n",
    "    'expected_delta_weighted_kappa': 'E[$\\Delta$Kappa]',\n",
    "    'dist_maxclass_prob_from_one': 'Max Class Prob.',\n",
    "    'entropy': 'Entropy',\n",
    "    'variance': 'MC Dropout Var.'\n",
    "}\n",
    "abstention_fractions = ['0.05', '0.1', '0.15', '0.2']\n",
    "\n",
    "for comparison_group_name in comparison_groups:\n",
    "    \n",
    "    print(\"On comparison group\", comparison_group_name)\n",
    "    columnstowrite = comparison_groups[comparison_group_name][1]\n",
    "    for metric in [\"weighted_kappa\",\n",
    "                   \"accuracy\"]:\n",
    "        print(\"On metric\", metric)\n",
    "        \n",
    "        #gather all the necessary data\n",
    "        settingnmethod_to_baselineperfs = OrderedDict()\n",
    "        settingnmethod_to_abstentionfraction_to_perfs = OrderedDict()\n",
    "        \n",
    "        for (settingsname, methodname) in comparison_groups[comparison_group_name][0]:\n",
    "            settingnmethod = settingsname+\"-\"+methodname\n",
    "            settingnmethod_to_baselineperfs[settingnmethod] =\\\n",
    "                settingsname_to_metric_to_baselineperfs[settingsname][metric]\n",
    "            \n",
    "            \n",
    "            abstentionfraction_to_perfs = OrderedDict()\n",
    "            settingnmethod_to_abstentionfraction_to_perfs[settingnmethod] =\\\n",
    "                abstentionfraction_to_perfs\n",
    "            for abstention_fraction in abstention_fractions:\n",
    "                abstentionfraction_to_perfs[abstention_fraction] = (\n",
    "                    settingsname_to_metric_to_fraction_to_method_to_perfs[\n",
    "                        settingsname][\"delta_\"+metric][abstention_fraction][\n",
    "                        methodname])\n",
    "        \n",
    "        #prepare the table contents\n",
    "        \n",
    "        settingnmethod_to_tablecontents = OrderedDict()\n",
    "        for settingnmethod in settingnmethod_to_baselineperfs:\n",
    "            tablerow = {}\n",
    "            settingnmethod_to_tablecontents[settingnmethod] = tablerow\n",
    "            tablerow['baseline'] = {\n",
    "                'mean': np.mean(settingnmethod_to_baselineperfs[settingnmethod]),\n",
    "                'stderr': np.std(settingnmethod_to_baselineperfs[settingnmethod],\n",
    "                                 ddof=1)/np.sqrt(num_folds)}\n",
    "            tablerow['method'] = settingnmethod.split(\"-\")[1]\n",
    "            tablerow['mcdr'] = \"mcdr\" in settingnmethod.split(\"-\")[0]\n",
    "            tablerow['calib'] = (\"uncalib\" in settingnmethod.split(\"-\")[0])==False\n",
    "            #if neither 'balanced' nor 'imbalanced' is in the name, it means balanced\n",
    "            tablerow['imbalanced'] = ((\"imbalanced\" in settingnmethod.split(\"-\")[0])\n",
    "                                      and (\"balanced\" in settingnmethod.split(\"-\")[0]))\n",
    "            #if neither adapted nor unadapted is in the name, it means no adaptation\n",
    "            tablerow['adapted'] = ((\"unadapted\" not in settingnmethod.split(\"-\")[0])\n",
    "                                     and (\"adapted\" in settingnmethod.split(\"-\")[0]))\n",
    "        \n",
    "        for abstention_fraction in abstention_fractions:\n",
    "            method_to_perfs = OrderedDict()\n",
    "            for settingnmethod in settingnmethod_to_tablecontents:\n",
    "                perfsdelta = settingnmethod_to_abstentionfraction_to_perfs[\n",
    "                    settingnmethod][abstention_fraction]\n",
    "                method_to_perfs[settingnmethod] = perfsdelta\n",
    "                mean_perfsdelta = np.mean(perfsdelta)\n",
    "                stderr_perfsdelta = (np.std(perfsdelta,ddof=1)/\n",
    "                                     np.sqrt(num_folds))\n",
    "                tablerow = settingnmethod_to_tablecontents[settingnmethod]\n",
    "                tablerow[abstention_fraction] = {\n",
    "                    'mean': mean_perfsdelta,\n",
    "                    'stderr': stderr_perfsdelta}\n",
    "            methods_to_consider = list(method_to_perfs.keys())\n",
    "            ustats_mat = get_ustats_mat(\n",
    "                method_to_perfs,\n",
    "                methods_to_consider,\n",
    "                max_ustat=1275)\n",
    "            tied_top_methods, tied_worst_methods =(\n",
    "                get_tied_top_and_worst_methods(\n",
    "                    ustats_mat,\n",
    "                    methods_to_consider,\n",
    "                    #0.05 threshold for one-sided test when N=119 is 50\n",
    "                    #http://www.real-statistics.com/statistics-tables/wilcoxon-signed-ranks-table/\n",
    "                    threshold=120\n",
    "                ))\n",
    "            tied_top_methods = [methods_to_consider[x]\n",
    "                                for x in tied_top_methods]\n",
    "            #print(abstention_fraction)\n",
    "            #print(tied_top_methods)\n",
    "            for settingnmethod in settingnmethod_to_tablecontents:\n",
    "                settingnmethod_to_tablecontents[\n",
    "                    settingnmethod][abstention_fraction][\n",
    "                    'istop'] = (settingnmethod in tied_top_methods)\n",
    "            #print(settingnmethod_to_tablecontents)\n",
    "            \n",
    "        thestr = \"\\\\begin{tabular}{ | c | c | c | c | c | c | c | }\\n\"\n",
    "        thestr += (\"\\\\hline Method & \"\n",
    "                  +('Calibrated?' if 'calib' in columnstowrite else '')\n",
    "                  +('Adapted?' if 'adapted' in columnstowrite else '')\n",
    "                  +\"& $\\\\Delta$ @\")\n",
    "        thestr += \" & $\\\\Delta$ @\".join([str(int(100*float(x)))+\"\\\\% Abs.\"\n",
    "                              for x in abstention_fractions])\n",
    "        thestr += \"\\\\\\\\ \\\\hline\\n\"\n",
    "        for settingnmethod in settingnmethod_to_tablecontents:\n",
    "            tablerow = settingnmethod_to_tablecontents[settingnmethod]\n",
    "            thestr += friendly_method_names[tablerow['method']]\n",
    "            thestr += \" & \"+str(tablerow['baseline']['mean'])\n",
    "            if ('calib' in columnstowrite):\n",
    "                thestr += \" & \"+(\"Y\" if tablerow['calib'] else \"N\")\n",
    "            if ('adapted' in columnstowrite):\n",
    "                thestr += \" & \"+(\"Y\" if tablerow['adapted'] else \"N\")\n",
    "            #thestr += \" & \"+(str(np.round(tablerow['baseline']['mean'],4))\n",
    "            #                 +\" $\\\\pm$ \"\n",
    "            #                 +str(np.round(tablerow['baseline']['stderr'],4)))\n",
    "            for abstention_fraction in abstention_fractions:\n",
    "                thestr += (\n",
    "                    \" & \"+\n",
    "                    (\"\\\\textbf{\" if tablerow[abstention_fraction]['istop'] else \"\")\n",
    "                    +str(np.round(tablerow[abstention_fraction]['mean'],4))\n",
    "                    +\" $\\\\pm$ \"\n",
    "                    +str(np.round(tablerow[abstention_fraction]['stderr'],4))\n",
    "                    +(\"}\" if tablerow[abstention_fraction]['istop'] else \"\"))\n",
    "            thestr += \"\\\\\\\\ \\hline\\n\"\n",
    "        thestr += \"\\\\end{tabular}\\n\"\n",
    "        \n",
    "        print(\"\\nBaseline \"+metric+\" perfs:\")\n",
    "        baseline_mean = set(\n",
    "                x['baseline']['mean'] for x in\n",
    "                settingnmethod_to_tablecontents.values())\n",
    "        print(baseline_mean)\n",
    "        #assert that all the methods have the same baseline\n",
    "        #assert len(baseline_mean)==1\n",
    "        #baseline_mean = list(baseline_mean)[0]\n",
    "        baseline_stderr = set(\n",
    "                x['baseline']['stderr'] for x in\n",
    "                settingnmethod_to_tablecontents.values())\n",
    "        print(baseline_stderr)\n",
    "        #assert len(baseline_stderr)==1\n",
    "        #baseline_stderr = list(baseline_stderr)[0]\n",
    "        #print(np.round(baseline_mean,4),\"$\\\\pm$\",np.round(baseline_stderr,4))\n",
    "        \n",
    "        print(\"\\n Latex Table for metric \"\n",
    "              +metric+\" and group \"+comparison_group_name\n",
    "              +\"\\n\\n\"+thestr)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
