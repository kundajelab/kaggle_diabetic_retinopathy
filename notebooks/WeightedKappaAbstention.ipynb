{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "valid_labels = LabelBinarizer().fit_transform(\n",
    "    np.array([float(x.decode(\"utf-8\").split(\"\\t\")[1])\n",
    "              for x in gzip.open(\"valid_labels.txt.gz\",'rb')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#augmenting the dataset with flips and rotaitons, for more robustness\n",
    "parent_folders = [\"flip-False_rotamt-0\",\n",
    "                  \"flip-True_rotamt-0\",\n",
    "                  \"flip-False_rotamt-90\",\n",
    "                  \"flip-True_rotamt-90\",\n",
    "                  \"flip-False_rotamt-180\",\n",
    "                  \"flip-True_rotamt-180\",]\n",
    "\n",
    "parent_folder_to_det_pred = {}\n",
    "for parent_folder in parent_folders:\n",
    "    det_preds = np.array([\n",
    "            [float(y) for y in x.decode(\"utf-8\").split(\"\\t\")[1:]]\n",
    "             for x in gzip.open(parent_folder+\"/deterministic_preds.txt.gz\", 'rb')])\n",
    "    parent_folder_to_det_pred[parent_folder] = det_preds\n",
    "    \n",
    "parent_folder_to_nondet_pred = {}\n",
    "parent_folder_to_mean_nondet_pred = {}\n",
    "for parent_folder in parent_folders:\n",
    "    nondet_preds = []\n",
    "    for i in range(100):\n",
    "        single_nondet_pred = np.array([\n",
    "            [float(y) for y in x.decode(\"utf-8\").split(\"\\t\")[1:]]\n",
    "             for x in gzip.open(\n",
    "              parent_folder+\"/nondeterministic_preds_\"+str(i)+\".txt.gz\", 'rb')])\n",
    "        nondet_preds.append(single_nondet_pred)\n",
    "    nondet_preds = np.array(nondet_preds)\n",
    "    parent_folder_to_nondet_pred[parent_folder] = nondet_preds\n",
    "    parent_folder_to_mean_nondet_pred[parent_folder] = np.mean(nondet_preds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip-False_rotamt-0\n",
      "deterministic pred auROC 0.9118638796723656\n",
      "nondeterministic pred auROC 0.9129881925522253\n",
      "flip-True_rotamt-0\n",
      "deterministic pred auROC 0.9136845292158645\n",
      "nondeterministic pred auROC 0.9141930341618936\n",
      "flip-False_rotamt-90\n",
      "deterministic pred auROC 0.9077797755493358\n",
      "nondeterministic pred auROC 0.9079080860318696\n",
      "flip-True_rotamt-90\n",
      "deterministic pred auROC 0.9072243126739039\n",
      "nondeterministic pred auROC 0.9084814670645733\n",
      "flip-False_rotamt-180\n",
      "deterministic pred auROC 0.916166708887612\n",
      "nondeterministic pred auROC 0.9166587373671843\n",
      "flip-True_rotamt-180\n",
      "deterministic pred auROC 0.9131712872857287\n",
      "nondeterministic pred auROC 0.9138490879246036\n"
     ]
    }
   ],
   "source": [
    "#Compute the auROC/auPRC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for parent_folder in parent_folders:\n",
    "    print(parent_folder)\n",
    "    det_preds = parent_folder_to_det_pred[parent_folder]\n",
    "    mean_nondet_preds = parent_folder_to_mean_nondet_pred[parent_folder]\n",
    "    print(\"deterministic pred auROC\",\n",
    "          roc_auc_score(y_true=1-valid_labels[:,0],\n",
    "                              y_score=1-det_preds[:,0]))\n",
    "    print(\"nondeterministic pred auROC\",\n",
    "          roc_auc_score(y_true=1-valid_labels[:,0],\n",
    "                              y_score=1-mean_nondet_preds[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstainer settings calib_weightrescalepreds\n",
      "on fold 0\n",
      "on fold 1\n",
      "on fold 2\n",
      "on fold 3\n",
      "on fold 4\n",
      "on fold 5\n",
      "on fold 6\n",
      "on fold 7\n",
      "on fold 8\n",
      "on fold 9\n",
      "on fold 10\n",
      "on fold 11\n",
      "on fold 12\n",
      "on fold 13\n",
      "on fold 14\n",
      "on fold 15\n",
      "on fold 16\n",
      "on fold 17\n",
      "on fold 18\n",
      "on fold 19\n",
      "on fold 20\n",
      "on fold 21\n",
      "on fold 22\n",
      "on fold 23\n",
      "on fold 24\n",
      "on fold 25\n",
      "on fold 26\n",
      "on fold 27\n",
      "on fold 28\n",
      "on fold 29\n",
      "on fold 30\n",
      "on fold 31\n",
      "on fold 32\n",
      "on fold"
     ]
    }
   ],
   "source": [
    "import abstention\n",
    "from abstention.calibration import compute_ece, TempScaling\n",
    "reload(abstention.abstention)\n",
    "from abstention.abstention import (weighted_kappa_metric,\n",
    "                                   WeightedKappa, DistMaxClassProbFromOne,\n",
    "                                   Entropy, Uncertainty)\n",
    "from collections import defaultdict, namedtuple\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def inverse_softmax(preds):\n",
    "    return np.log(preds) - np.mean(np.log(preds),axis=1)[:,None]\n",
    "\n",
    "quadratic_weights = np.array([[(i-j)**2 for i in range(5)]\n",
    "                             for j in range(5)])\n",
    "\n",
    "AbstainerSettings = namedtuple(\"AbstainerSettings\",\n",
    "                               [\"name\",\n",
    "                                \"abstainer_factories\",\n",
    "                                \"preds_lookup\",\n",
    "                                \"predsamples_lookup\",\n",
    "                                \"use_calib\"])\n",
    "\n",
    "abstainer_factories = [\n",
    "        (\"expected_delta_weighted_kappa\", WeightedKappa(\n",
    "            weights=quadratic_weights, verbose=False)),\n",
    "        (\"expected_delta_weighted_kappa_imbalance_from_valid\", WeightedKappa(\n",
    "                weights=quadratic_weights,\n",
    "                estimate_class_imbalance_from_valid=True,\n",
    "                verbose=False)),\n",
    "        (\"dist_maxclass_prob_from_one\", DistMaxClassProbFromOne()),\n",
    "        (\"entropy\", Entropy()),\n",
    "        (\"variance\", Uncertainty())]\n",
    "abstention_fractions = [0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "abstainer_settings_list = [\n",
    "    AbstainerSettings(\n",
    "        name=\"calib_weightrescalepreds\",\n",
    "        abstainer_factories=abstainer_factories,\n",
    "        preds_lookup=parent_folder_to_det_pred,\n",
    "        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "        use_calib=True),\n",
    "    AbstainerSettings(\n",
    "        name=\"uncalib_weightrescalepreds\",\n",
    "        abstainer_factories=abstainer_factories,\n",
    "        preds_lookup=parent_folder_to_det_pred,\n",
    "        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "        use_calib=False),\n",
    "    AbstainerSettings(\n",
    "        name=\"calib_mcdrpreds\",\n",
    "        abstainer_factories=abstainer_factories,\n",
    "        preds_lookup=parent_folder_to_mean_nondet_pred,\n",
    "        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "        use_calib=True),\n",
    "    AbstainerSettings(\n",
    "        name=\"uncalib_mcdrpreds\",\n",
    "        abstainer_factories=abstainer_factories,\n",
    "        preds_lookup=parent_folder_to_mean_nondet_pred,\n",
    "        predsamples_lookup=parent_folder_to_nondet_pred,\n",
    "        use_calib=False)\n",
    "]\n",
    "\n",
    "num_folds = 50\n",
    "\n",
    "settingsname_to_metric_to_fraction_to_method_to_perfs = {}\n",
    "settingsname_to_metric_to_baselineperfs = {}\n",
    "\n",
    "for abstainer_settings in abstainer_settings_list:\n",
    "    \n",
    "    settings_name = abstainer_settings.name\n",
    "    print(\"abstainer settings\", settings_name)\n",
    "    abstainer_factories = abstainer_settings.abstainer_factories\n",
    "    preds_lookup = abstainer_settings.preds_lookup\n",
    "    predsamples_lookup = abstainer_settings.predsamples_lookup\n",
    "    use_calib = abstainer_settings.use_calib\n",
    "    \n",
    "    metric_to_fraction_to_method_to_perfs =\\\n",
    "        defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    settingsname_to_metric_to_fraction_to_method_to_perfs[settings_name] =\\\n",
    "        metric_to_fraction_to_method_to_perfs\n",
    "    metric_to_baselineperfs = defaultdict(list)   \n",
    "    settingsname_to_metric_to_baselineperfs[settings_name] =\\\n",
    "        metric_to_baselineperfs\n",
    "    \n",
    "    for fold_number in range(num_folds):\n",
    "        print(\"on fold\",fold_number)\n",
    "\n",
    "        np.random.seed(fold_number*1000)\n",
    "        random.seed(fold_number*1000)\n",
    "        #the data is in pairs of (left eye, right eye) per patient (entry for\n",
    "        # the right eye comes after the entry for the left eye); hence, the number of\n",
    "        # unique patients is 0.5*len(valid_labels)\n",
    "        patient_id_ordering = list(range(int(0.5*len(valid_labels))))\n",
    "        np.random.shuffle(patient_id_ordering)\n",
    "\n",
    "        pseudovalid_uncalib_preds = []\n",
    "        pseudotest_uncalib_preds = []\n",
    "        pseudovalid_uncalib_predsamples = []\n",
    "        pseudotest_uncalib_predsamples = []\n",
    "        pseudovalid_labels = []\n",
    "        pseudotest_labels = []\n",
    "        pseudovalid_label_counts = np.zeros(5)\n",
    "        pseudotest_label_counts = np.zeros(5)\n",
    "        for i in patient_id_ordering:\n",
    "            left_eye_label = valid_labels[2*i]\n",
    "            right_eye_label = valid_labels[(2*i)+1]\n",
    "            most_diseased_label = max(np.argmax(left_eye_label),\n",
    "                                      np.argmax(right_eye_label))\n",
    "            if (pseudovalid_label_counts[most_diseased_label] <\n",
    "                pseudotest_label_counts[most_diseased_label]):\n",
    "                append_to_uncalib_preds = pseudovalid_uncalib_preds\n",
    "                append_to_uncalib_predsamples = pseudovalid_uncalib_predsamples\n",
    "                append_to_labels = pseudovalid_labels\n",
    "                append_to_label_counts = pseudovalid_label_counts\n",
    "            else:\n",
    "                append_to_uncalib_preds = pseudotest_uncalib_preds\n",
    "                append_to_uncalib_predsamples = pseudotest_uncalib_predsamples\n",
    "                append_to_labels = pseudotest_labels\n",
    "                append_to_label_counts = pseudotest_label_counts\n",
    "\n",
    "            for parent_folder in parent_folders:        \n",
    "                append_to_labels.append(valid_labels[2*i])\n",
    "                append_to_labels.append(valid_labels[(2*i)+1])\n",
    "                append_to_label_counts += valid_labels[2*i]\n",
    "                append_to_label_counts += valid_labels[(2*i)+1]\n",
    "                append_to_uncalib_preds.append(\n",
    "                        preds_lookup[parent_folder][2*i])\n",
    "                append_to_uncalib_preds.append(\n",
    "                        preds_lookup[parent_folder][(2*i)+1])\n",
    "                append_to_uncalib_predsamples.append(\n",
    "                        predsamples_lookup[parent_folder][:,(2*i)])\n",
    "                append_to_uncalib_predsamples.append(\n",
    "                        predsamples_lookup[parent_folder][:,(2*i)+1])\n",
    "\n",
    "        pseudovalid_uncalib_preds = np.array(pseudovalid_uncalib_preds)\n",
    "        pseudotest_uncalib_preds = np.array(pseudotest_uncalib_preds)\n",
    "        pseudovalid_uncalib_pred_logits = inverse_softmax(pseudovalid_uncalib_preds)\n",
    "        pseudotest_uncalib_pred_logits = inverse_softmax(pseudotest_uncalib_preds)\n",
    "        pseudovalid_uncalib_predsamples = np.array(pseudovalid_uncalib_predsamples).transpose((1,0,2))\n",
    "        pseudotest_uncalib_predsamples = np.array(pseudotest_uncalib_predsamples).transpose((1,0,2))\n",
    "        pseudovalid_uncalib_predsamples_logits = np.array([\n",
    "                inverse_softmax(x) for x in pseudovalid_uncalib_predsamples])        \n",
    "        pseudotest_uncalib_predsamples_logits = np.array([\n",
    "                inverse_softmax(x) for x in pseudotest_uncalib_predsamples])\n",
    "        pseudovalid_labels = np.array(pseudovalid_labels) \n",
    "        pseudotest_labels = np.array(pseudotest_labels)\n",
    "        #print(\"valid vs. test distribution shift\",\n",
    "        #      np.abs(pseudovalid_label_counts-pseudotest_label_counts)/\n",
    "        #            (pseudovalid_label_counts+pseudotest_label_counts))\n",
    "        \n",
    "        pseudovalid_uncalib_variance = np.sum(np.var(pseudovalid_uncalib_predsamples,axis=0),axis=-1)\n",
    "        pseudotest_uncalib_variance = np.sum(np.var(pseudotest_uncalib_predsamples,axis=0),axis=-1)\n",
    "        \n",
    "        if (use_calib):\n",
    "            #print(\"ece before temp scale - valid\",\n",
    "            #  compute_ece(softmax_out=pseudovalid_uncalib_preds,\n",
    "            #              labels=pseudovalid_labels,\n",
    "            #              bins=15))\n",
    "            #print(\"ece before temp scale - test\",\n",
    "            #      compute_ece(softmax_out=pseudotest_uncalib_preds,\n",
    "            #                  labels=pseudotest_labels,\n",
    "            #                  bins=15))\n",
    "            temp_scaler = TempScaling(ece_bins=15, verbose=False)(\n",
    "                                valid_preacts=pseudovalid_uncalib_pred_logits,\n",
    "                                valid_labels=pseudovalid_labels)\n",
    "            pseudovalid_calib_preds = temp_scaler(pseudovalid_uncalib_pred_logits)\n",
    "            pseudotest_calib_preds = temp_scaler(pseudotest_uncalib_pred_logits)\n",
    "            pseudovalid_calib_predsamples = np.array(\n",
    "                [temp_scaler(x) for x in pseudovalid_uncalib_predsamples_logits])\n",
    "            pseudotest_calib_predsamples = np.array(\n",
    "                [temp_scaler(x) for x in pseudotest_uncalib_predsamples_logits])\n",
    "            \n",
    "            pseudovalid_calib_variance = np.sum(np.var(pseudovalid_calib_predsamples, axis=0),axis=-1)\n",
    "            pseudotest_calib_variance = np.sum(np.var(pseudotest_calib_predsamples, axis=0),axis=-1)\n",
    "\n",
    "            #print(\"ece after temp scale - valid\",\n",
    "            #      compute_ece(softmax_out=pseudovalid_calib_preds,\n",
    "            #            labels=pseudovalid_labels,\n",
    "            #            bins=15))\n",
    "            #print(\"ece after temp scale - test\",\n",
    "            #      compute_ece(softmax_out=pseudotest_calib_preds,\n",
    "            #            labels=pseudotest_labels,\n",
    "            #            bins=15))\n",
    "            \n",
    "        if (use_calib):\n",
    "            pseudotest_preds_to_use=pseudotest_calib_preds\n",
    "            pseudovalid_preds_to_use=pseudovalid_calib_preds\n",
    "            pseudotest_variance_to_use=pseudotest_calib_variance\n",
    "            pseudovalid_variance_to_use=pseudovalid_calib_variance\n",
    "        else:\n",
    "            pseudotest_preds_to_use=pseudotest_uncalib_preds\n",
    "            pseudovalid_preds_to_use=pseudovalid_uncalib_preds\n",
    "            pseudotest_variance_to_use=pseudotest_uncalib_variance\n",
    "            pseudovalid_variance_to_use=pseudovalid_uncalib_variance\n",
    "\n",
    "        original_weighted_kappa_perf = weighted_kappa_metric(\n",
    "            predprobs=pseudotest_preds_to_use,\n",
    "            true_labels=pseudotest_labels,\n",
    "            weights=quadratic_weights)\n",
    "        \n",
    "        #print(\"\\nPseudotest set weighted kappa\",\n",
    "        #      original_weighted_kappa_perf)\n",
    "        metric_to_baselineperfs[\"weighted_kappa\"].append(\n",
    "            original_weighted_kappa_perf)\n",
    "        original_accuracy_perf = np.mean(\n",
    "            np.argmax(pseudotest_preds_to_use,axis=-1)\n",
    "            ==np.argmax(pseudotest_labels,axis=-1))\n",
    "        #print(\"Pseudotest set accuracy\",original_accuracy_perf)\n",
    "        metric_to_baselineperfs[\"accuracy\"].append(original_accuracy_perf)\n",
    "\n",
    "        for abstention_fraction in abstention_fractions:\n",
    "            #print(\"\\nabstention fraction:\",abstention_fraction)\n",
    "            for abstainer_name, abstainer_factory in abstainer_factories:\n",
    "                abstainer = abstainer_factory(\n",
    "                    valid_labels=pseudovalid_labels,\n",
    "                    valid_posterior=pseudovalid_preds_to_use)\n",
    "                abstainer_priorities = abstainer(\n",
    "                    posterior_probs=pseudotest_preds_to_use,\n",
    "                    uncertainties=pseudotest_variance_to_use)\n",
    "                indices_to_retain = (\n",
    "                    [y[0] for y in sorted(enumerate(abstainer_priorities),\n",
    "                        key=lambda x: x[1])][:int(len(abstainer_priorities)*\n",
    "                                                     (1-abstention_fraction))])\n",
    "                retained_pseudotest_preds = np.array(\n",
    "                    [pseudotest_preds_to_use[i] for i in indices_to_retain])\n",
    "                retained_pseudotest_labels = np.array(\n",
    "                    [pseudotest_labels[i] for i in indices_to_retain])\n",
    "                #print(\"\\nAbstention criterion:\",abstainer_name)\n",
    "                weighted_kappa_perf = weighted_kappa_metric(\n",
    "                    predprobs=retained_pseudotest_preds,\n",
    "                    true_labels=retained_pseudotest_labels,\n",
    "                    weights=quadratic_weights)\n",
    "                #print(\"weighted kappa\", weighted_kappa_perf)\n",
    "                accuracy_perf = (np.mean(np.argmax(\n",
    "                    retained_pseudotest_preds,axis=-1)\n",
    "                    ==np.argmax(retained_pseudotest_labels,axis=-1)))\n",
    "                #print(\"accuracy\", accuracy_perf)\n",
    "\n",
    "                metric_to_fraction_to_method_to_perfs[\"delta_weighted_kappa\"][\n",
    "                    abstention_fraction][abstainer_name].append(\n",
    "                        weighted_kappa_perf-original_weighted_kappa_perf)\n",
    "                metric_to_fraction_to_method_to_perfs[\"delta_accuracy\"][\n",
    "                    abstention_fraction][abstainer_name].append(\n",
    "                        accuracy_perf-original_accuracy_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from abstention.figure_making_utils import (\n",
    "    wilcox_srs, get_ustats_mat, get_tied_top_and_worst_methods)\n",
    "\n",
    "methods_to_consider = ['expected_delta_weighted_kappa',\n",
    "                       'dist_maxclass_prob_from_one',\n",
    "                       'entropy']\n",
    "for metric in [\"delta_weighted_kappa\", \"delta_accuracy\"]:\n",
    "    for abstention_fraction_to_consider in [0.05, 0.2]:   \n",
    "        ustats_mat = get_ustats_mat(\n",
    "            metric_to_fraction_to_method_to_perfs[metric][abstention_fraction_to_consider],\n",
    "            methods_to_consider)\n",
    "        \n",
    "        tied_top_methods, tied_worst_methods =(\n",
    "            get_tied_top_and_worst_methods(ustats_mat, methods_to_consider))\n",
    "        print(\"\\nAbstention fraction\",abstention_fraction_to_consider,\"with metric\",metric)\n",
    "        \n",
    "        method_to_perf_deltas = metric_to_fraction_to_method_to_perfs[\n",
    "                                 metric][abstention_fraction_to_consider]\n",
    "        \n",
    "        print(\"\\nMethods sorted by mean delta perf:\")\n",
    "        print(\"\\n\".join(\n",
    "                [str(x[0])\n",
    "                 +\"\\t\"+str(np.round(x[1],5))\n",
    "                 +\" +/- \"\n",
    "                 +str(np.round(np.std(method_to_perf_deltas[x[0]],ddof=1)/\n",
    "                               np.sqrt(num_folds),5)) #standard error \n",
    "                #sort the different methods by their mean delta perf\n",
    "                for x in sorted([\n",
    "                    (method_name,np.mean(method_to_perf_deltas[method_name]))\n",
    "                     for method_name in methods_to_consider],\n",
    "                    key=lambda x: -x[1])\n",
    "                ]))\n",
    "        \n",
    "        print(\"\\nTop methods by wilcoxon:\",[methods_to_consider[x] for x in tied_top_methods])\n",
    "        print(\"Worst methods by wilcoxon:\",[methods_to_consider[x] for x in tied_worst_methods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
